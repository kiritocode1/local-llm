{
  "name": "@blank-utils/llm",
  "version": "0.3.2",
  "description": "Run LLMs directly in your browser with WebGPU acceleration. Supports React hooks and eager background loading.",
  "type": "module",
  "main": "./dist/index.js",
  "module": "./dist/index.js",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "import": "./dist/index.js",
      "default": "./dist/index.js"
    },
    "./react": {
      "types": "./dist/react/index.d.ts",
      "import": "./dist/react/index.js",
      "default": "./dist/react/index.js"
    },
    "./package.json": "./package.json"
  },
  "typesVersions": {
    "*": {
      ".": [
        "./dist/index.d.ts"
      ],
      "react": [
        "./dist/react/index.d.ts"
      ]
    }
  },
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "dev": "bun --watch ./src/index.ts",
    "clean": "rm -rf dist",
    "build:js": "bun build ./src/index.ts --outfile ./dist/index.js --format esm --external react --external react-dom --external streamdown --external @streamdown/code --external @streamdown/mermaid && bun build ./src/react/index.tsx --outfile ./dist/react/index.js --format esm --external react --external react-dom --external streamdown --external @streamdown/code --external @streamdown/mermaid",
    "postbuild": "mkdir -p dist/react && cp node_modules/@huggingface/transformers/dist/*.wasm dist/ && cp node_modules/onnxruntime-web/dist/*.mjs dist/ && cp node_modules/onnxruntime-web/dist/*.wasm dist/ && cp dist/*.wasm dist/react/ 2>/dev/null || true && cp dist/*.mjs dist/react/ 2>/dev/null || true",
    "build:types": "tsc -p tsconfig.build.json",
    "build": "bun run clean && bun run build:js && bun run postbuild && bun run build:types",
    "prepublishOnly": "bun run build",
    "demo": "bunx serve . -p 3000",
    "typecheck": "tsc --noEmit",
    "test": "bun test",
    "deploy": "bun run build && npm publish --access public --ignore-scripts"
  },
  "keywords": [
    "llm",
    "ai",
    "browser",
    "webgpu",
    "webllm",
    "transformers",
    "local",
    "inference",
    "react",
    "hooks",
    "streaming",
    "chat",
    "gpt",
    "huggingface"
  ],
  "author": "blank",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/kiritocode1/local-llm.git"
  },
  "homepage": "https://github.com/kiritocode1/local-llm#readme",
  "bugs": {
    "url": "https://github.com/kiritocode1/local-llm/issues"
  },
  "publishConfig": {
    "access": "public"
  },
  "engines": {
    "node": ">=18"
  },
  "devDependencies": {
    "@types/bun": "latest",
    "@types/react": "^18.3.0 || ^19.0.0",
    "@webgpu/types": "^0.1.69",
    "typescript": "^5.9.3"
  },
  "peerDependencies": {
    "react": ">=18.0.0"
  },
  "peerDependenciesMeta": {
    "react": {
      "optional": true
    }
  },
  "dependencies": {
    "@huggingface/transformers": "^3.8.1",
    "@mlc-ai/web-llm": "^0.2.80",
    "@streamdown/code": "^1.0.2",
    "@streamdown/mermaid": "^1.0.2",
    "streamdown": "^2.2.0"
  }
}
